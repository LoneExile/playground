# base kube

## [cert-manager](https://cert-manager.io/docs/installation/#default-static-install)

```bash
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.0/cert-manager.yaml
```

## [metallb](https://metallb.universe.tf/installation/#installation-by-manifest)

```bash
kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.11/config/manifests/metallb-native.yaml
wget https://raw.githubusercontent.com/LoneExile/playground/main/cookbook/k3s/metallb-layer2.yaml
kubectl apply -f metallb-layer2.yaml
```

## prometheus

```bash
git clone https://github.com/prometheus-operator/kube-prometheus.git
cd kube-prometheus
kubectl create -f manifests/setup
until kubectl get servicemonitors --all-namespaces ; do date; sleep 1; echo ""; done
kubectl create -f manifests/
kubectl delete networkpolicy grafana -n monitoring
```

## rook-ceph

### install rook-ceph

```bash
git clone --single-branch --branch v1.12.4 https://github.com/rook/rook.git
cd rook/deploy/examples
kubectl create -f crds.yaml -f common.yaml -f operator.yaml
```

```bash
kubectl create -f cluster.yaml
```

```bash
kubectl create -f toolbox.yaml
```

```bash
# kubectl create -f storageclass.yaml
# kubectl create -f filesystem.yaml
# kubectl create -f object.yaml
# kubectl create -f pool.yaml
```

### uninstall rook-ceph

```bash
kubectl delete -f cluster.yaml -n rook-ceph
```

```bash
kubectl delete -f toolbox.yaml -f operator.yaml -n rook-ceph
```

```bash
kubectl delete -f common.yaml -f crds.yaml -n rook-ceph
```

```bash
sudo rm -rf /var/lib/rook
```

## format and mount cephfs

```bash
sudo fdisk /dev/sda

sudo mkfs.ext4 /dev/mmcblk0p3
# sudo mkfs.ext4 /dev/sda1

## remove filesystem
sudo dd if=/dev/zero of=/dev/mmcblk0p3 bs=1M count=100

## check filesystem
lsblk -f

# -------
# set name in cluster.yaml
# kubectl get node orangepi5 --show-labels
# NAME        STATUS   ROLES                  AGE   VERSION        LABELS
# orangepi5   Ready    control-plane,master   25h   v1.27.4+k3s1   beta.kubernetes.io/arch=arm64,beta.kubernetes.io/instance-type=k3s,beta.kubernetes.io/os=linux,kubernetes.io/arch=arm64,kubernetes.io/hostname=orangepi5,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=true,node-role.kubernetes.io/master=true,node.kubernetes.io/instance-type=k3s
# -------


## mount cephfs
# sudo mkdir -p /mnt/cephfs
# sudo mount -t ext4 /dev/sda1 /mnt/cephfs
# sudo chmod 777 /mnt/cephfs
# sudo chown -R 1000:1000 /mnt/cephfs

## umount cephfs
# sudo umount /mnt/cephfs
# sudo rm -rf /mnt/cephfs
# sudo rm -rf /var/lib/rook

```

### Adding an OSD
```bash
ceph orch daemon add osd node1:/dev/sda1

## set OSD device class for osd.0 to SSD
# ceph osd crush set-device-class ssd osd.0

## if already set, remove the device class before
# ceph osd crush rm-device-class osd.0
```

### Removing an OSD
```bash
ceph osd out osd.<OSD_ID>
```

```bash
ceph osd purge osd.<OSD_ID> --yes-i-really-mean-it
```

```bash
kubectl -n rook-ceph delete deployment rook-ceph-osd-<OSD_ID>
```

### Reuse existing drives
```bash
## If you're adding a disk that has been used (at least partitioned) before, ceph will require that you clear (zap in ceph jargon) the device before.
ceph orch device zap <HOST> <DEVICE> --force

# ceph balancer status
# ceph balancer mode upmap 
# ceph balancer on
```
